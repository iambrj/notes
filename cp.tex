\documentclass[titlepage, 12pt]{book}
\usepackage[parfill]{parskip}
\usepackage{amsmath}
\usepackage{xcolor}
\usepackage{amsfonts}
\usepackage{setspace}
\usepackage{hyperref}
\usepackage{tcolorbox}
\tcbuselibrary{theorems}

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,
    urlcolor=blue,
}

\newtcbtheorem[]{definition}{Definition}%
{colback=magenta!5,colframe=magenta!100!black,fonttitle=\bfseries}{th}

\newtcbtheorem[]{proposition}{Proposition}%
{colback=cyan!5,colframe=cyan!100!black,fonttitle=\bfseries}{th}

\newtcbtheorem[]{theorem}{Theorem}%
{colback=orange!5,colframe=orange!100!black,fonttitle=\bfseries}{th}

\newtcbtheorem[]{algorithm}{Algorithm}%
{colback=violet!5,colframe=violet!100!black,fonttitle=\bfseries}{th}

\begin{document}

\begin{titlepage}

	\raggedleft

	\vspace*{\baselineskip}

	{Bharathi Ramana Joshi\\\url{https://github.com/iambrj/notes}}

	\vspace*{0.167\textheight}

	\textbf{\LARGE Notes on competitive programming}\\[\baselineskip]

	\vfill

	\vspace*{3\baselineskip}

\end{titlepage}

\newpage

\tableofcontents

\chapter{Performance}

\begin{definition}{Operations per second}{}
    Most judges allow $10^8$ operations per second, but all allow $10^7$.
\end{definition}

Always pass arguments by reference when possible.

\chapter{Math}

\begin{definition}{Binet's formula for Fibonacci numbers}{}
    \begin{align*}
        f(n) = \frac{(1 + \sqrt{5}) ^ n - (1 - \sqrt{5}) ^ n}{2^n\sqrt{5}}
    \end{align*}
\end{definition}

\chapter{Arrays}

\begin{algorithm}{Kadane's algorithm}{}
    Finds the max subarray in $O(n)$. Idea : for each array element find the max
    subarray ending at that element. This subarray either
    \begin{enumerate}
        \item contains only the element at position $k$
        \item subarray that ends at $k - 1$ followed by element at $k$
    \end{enumerate}
    Implementation
    \begin{verbatim}
    int best = 0, sum = 0;
    for (int k = 0; k < n; k++) {
        sum = max(array[k], sum + array[k]);
        best = max(best, sum);
    }
    \end{verbatim}
\end{algorithm}

\begin{algorithm}{Prefix sum}{}
    Prefix sum, as the name suggests, keeps track of the cumulative sum; i.e. if
    $A =  [x_1,\dots,x_n]$ then prefix sum $P = [x_1, x_1 + x_2,\dots,x_n + x_{n
    - 1} + \dots x_1]$. It can be used to collapse an extra iteration. Key
    observation : useful when there is an underlying group structure and
    inverses are to be calculated repeatedly (e.g. $-(a_1+\dots+a_k) +
    (a_1+\dots+a_k+\dots+a_n)$).

    Some examples
    \begin{enumerate}
        \item Finding an index in an array such that sum of left subarray is
            same as sum of right subarray. The naive solution would run in
            $O(n^2)$ by calculating left and right subarray sums for each index.
            Using prefix sum however, this can be done in $O(n)$ in two disjoint
            iterations in opposite direction.
        \item Finding if there is a subarray that sums to 0. The naive solution
            would again take $O(n^2)$, by checking if all possible subarrays are
            nonzero. Using prefix sum, we can maintain a set of sums that have
            been so far. If a sum is repeated, it means there is a zero sum
            subarray. Exact subarray can be located by tracking indices of each
            sum.
        \item Integer with maximum frequency, given a list of ranges $[L_i,
            R_i]$. The naive approach again takes $O(n^2)$ by creating a
            frequency table for each integer. Instead, if the minimum $L_i$ and
            maximum $R_i$ are known, we can have an array $A[min(L_i),
            max(R_i)]$ and increment $A[L_i] += 1$ and decrement $A[R_i] -= 1$
            for each i, take a prefix sum to get the frequencies in $O(n)$.
    \end{enumerate}
\end{algorithm}

\begin{algorithm}{Two pointers}{}
    As the name suggests, two pointers are used to traverse the array. This can
    also be used to collapse $O(n^2)$ to $O(n)$ in some problems. The invariant
    to spot is each element $a_i$ has an associated range $[L_i, R_i]$ such that
    whenever $i\leq j$, $L_i\leq L_j$.

    Some examples
    \begin{enumerate}
        \item Given a sorted array $A$, find indices $i$ and $j$ such that $A[i]
            + A[j] = x$, for given $x$.
    \end{enumerate}
\end{algorithm}

\begin{algorithm}{Binary search}{}
    The technique to always get a binary search right is to maintain an
    \textit{invariant}: a condition that holds throughout the execution of the
    program. This means that it should hold at:
    \begin{enumerate}
        \item The beginning of the loop.
        \item During each iteration of the loop --- in other words, whatever
            a single iteration of the loop does to the program state, the
            invariant should still hold if it holds before the iteration.
        \item At the end of the loop.
    \end{enumerate}
    A useful invariant is $inRange(L, R)$ i.e. the answer we're looking for is
    in the range the binary search is currently in.
\end{algorithm}
As an exercise of the above idea, try to implement \verb|lower_bound| and
\verb|upper_bound|.

\chapter{Graphs}

\section{Fundamental}

\begin{algorithm}{BFS}{}
    Have a queue, and push neighbours of head of queue in each iteration.
    \begin{verbatim}
vector<vector<int>> adj;  // adjacency list representation
int n; // number of nodes
int s; // source vertex

queue<int> q;
vector<bool> used(n);
vector<int> d(n), p(n);

q.push(s);
used[s] = true;
p[s] = -1;
while (!q.empty()) {
    int v = q.front();
    q.pop();
    for (int u : adj[v]) {
        if (!used[u]) {
            used[u] = true;
            q.push(u);
            d[u] = d[v] + 1;
            p[u] = v;
        }
    }
}
    \end{verbatim}

Complexity $O(|V| + |E|)$

\end{algorithm}
Applications

\begin{enumerate}
    \item Single source shortest paths in unweighted graphs.
    \item Connected components in undirected graph : run BFS repeatedly until
        all vertices are visited.
    \item Optimal gameplay : vertices represent states, edges transitions
        between states. Smallest path is optimal play.
    \item Shortest cycle 
\end{enumerate}

\begin{algorithm}{DFS}{}
    Have a stack, and push neighbours of top of stack in each iteration.
    \begin{verbatim}
    \end{verbatim}

Complexity $O(|V| + |E|)$

\end{algorithm}
Applications

\begin{enumerate}
    \item Single source paths.
    \item Ancestry checking : check $i$ is $j$'s ancestor iff entry[$i] <$
        entry[$j$] and exit[$i] >$ exit[$j$].
    \item Finding lowest common ancestor of two vertices
    \item Topological sort : run DFS repeatedly until each vertex is visited
        exactly once, topological sort is descending order of exit time
    \item Cycle checking : "back" edge in DFS tree indicates cycle. Find DFS
        tree, then walk this tree. Use a stack to merge DFS with tree traversal.
        For directed graphs,
        \begin{verbatim}
// color scheme                                                 
// 0 -> unvisited
// 1 -> entered
// 2 -> exited
bool dfs(int v) {
    if(!color[v]) {
        color[v] = 1;
        for (auto u : adj[v]) {
            if (color[u] == 0) {
                parent[u] = v;
                if (dfs(u))
                    return true;
            } else if (color[u] == 1) {
                cycle_end = v;
                cycle_start = u;
                return true;
            }
        }
        color[v] = 2;
        return false;
    }    
}        
         
bool find_cycle() {
    // initialize color and parent
    cycle_start = -1;
         
    for (int v = 0; v < n; v++) {
        if (!color[v] && dfs(v))
            break;
    }    
         
    if (cycle_start == -1) {
        return false;
    } else {
        vector<int> cycle;
        cycle.push_back(cycle_start);
        for (int v = cycle_end; v != cycle_start; v = parent[v])
            cycle.push_back(v);
        cycle.push_back(cycle_start);
        reverse(cycle.begin(), cycle.end());
        return cycle;
    }    
}                               
        \end{verbatim}
        And for undirected graphs
\begin{verbatim}
bool dfs(int v, int par) { // passing vertex and its parent vertex  
    if(!vis[v]) {
        vis[v] = true;          
        for (auto u : adj[v]) {     
            if(u == par) continue; // skipping edge to parent vertex
            if (vis[u]) {       
                cycle_end = v;      
                cycle_start = u;    
                return true;        
            }                       
            parent[u] = v;          
            if (dfs(u, parent[u]))  
                return true;        
        }                           
        return false;               
    }                               
}                                   
                
void find_cycle() {
    // initalize visited and parent
    cycle_start = -1;
                
    for (int v = 0; v < n; v++) {
        if (!vis[v] && dfs(v, parent[v]))
            break;
    }           
                
    if (cycle_start == -1) {
        return true;
    } else {    
        vector<int> cycle;
        cycle.push_back(cycle_start);
        for (int v = cycle_end; v != cycle_start; v = parent[v])
            cycle.push_back(v);
        cycle.push_back(cycle_start);
        reverse(cycle.begin(), cycle.end());
 
        cout << "Cycle found: ";
        for (int v : cycle)
            cout << v << " ";
        cout << endl;
    }           
}               
\end{verbatim}
    \item Finding SCC : Kosaraju's algorithm
\end{enumerate}

\begin{algorithm}{Kosaraju's algorithm}{}
\begin{verbatim}
vector<vector<int>> adj, adj_rev;
vector<bool> vis;
vector<int> order, component;

void dfs1(int v) {
    vis[v] = true;

    for (auto u : adj[v])
        if (!vis[u])
            dfs1(u);

    order.push_back(v);
}

void dfs2(int v) {
    vis[v] = true;
    component.push_back(v);

    for (auto u : adj_rev[v])
        if (!vis[u])
            dfs2(u);
}
 
int main() {
    //... read inputs ...
    vis.assign(n, false);

    for (int i = 0; i < n; i++)
        if (!vis[i])
            dfs1(i);

    vis.assign(n, false);
    reverse(order.begin(), order.end());

    for (auto v : order)
        if (!vis[v]) {
            dfs2 (v);

            // ... processing next component ...

            component.clear();
        }
}
\end{verbatim}
\end{algorithm}

\section{Shortest paths}

\begin{algorithm}{Dijkstra}{}
    Dijkstra spreads like fire
\begin{verbatim}
const int INF = 1000000000;
vector<vector<pair<int, int>>> adj;

void dijkstra(int s, vector<int> & d, vector<int> & p) {
    int n = adj.size();
    d.assign(n, INF);
    p.assign(n, -1);
    vector<bool> u(n, false);

    d[s] = 0;
    for (int i = 0; i < n; i++) {
        int v = -1;
        for (int j = 0; j < n; j++) {
            if (!u[j] && (v == -1 || d[j] < d[v]))
                v = j;
        }

        if (d[v] == INF)
            break;

        u[v] = true;
        for (auto adj : adj[v]) {
            int to = adj.first;
            int len = adj.second;

            if (d[v] + len < d[to]) {
                d[to] = d[v] + len;
                p[to] = v;
            }
        }
    }
}
\end{verbatim}


Complexity $O(|V|^2 + |E|)$

\end{algorithm}

\begin{algorithm}{Bellman-Ford}{}
Perform relaxations $|V|$ times.
\begin{verbatim}
struct edge
{
    int a, b, cost;
};

int n, m, v;
vector<edge> e;
const int INF = 1000000000;

void solve()
{
    vector<int> d (n, INF);
    d[v] = 0;
    for (int i=0; i<n-1; ++i)
        for (int j=0; j<m; ++j)
            if (d[e[j].a] < INF)
                d[e[j].b] = min (d[e[j].b],
                                 d[e[j].a] + e[j].cost);
}
\end{verbatim}

Complexity $O(|V| \times |E|)$

\end{algorithm}

\begin{algorithm}{Floyd-Warshall}{}
Bellman-Ford for all vertices
\begin{verbatim}
for (int k = 0; k < n; ++k) {
    for (int i = 0; i < n; ++i) {
        for (int j = 0; j < n; ++j) {
            d[i][j] = min(d[i][j], d[i][k] + d[k][j]); 
        }
    }
}
\end{verbatim}

Complexity $O(|V|^3)$

\end{algorithm}

\section{Advanced}

\begin{theorem}{Berge's lemma}{}
    \begin{enumerate}
        \item A \textbf{matching} in an undirected graph is a set of edges without
            common vertices
        \item A \textbf{maximum matching} contains largest possible number of edges
        \item An \textbf{augmenting path} is a path that starts and ends on
            unmatched vertices, and alternates between edges in and not in the
            matching
    \end{enumerate}
    \textbf{Berge's lemma} states that a matching $M$ in a graph $G$ is maximum,
    iff there is no augmenting path with $M$
\end{theorem}
\textbf{Backward Proof:}
If there is an augmenting path $P$ for the matching $M$ in a graph $G$, then
observe that the symmetric difference of $P$ and $M$ forms a matching with 1
more than $M$.

\textbf{Forward Proof:}
Let $M'$ be the matching larger than $M$ in $G$. Let $D$ be the symmetric
difference of $M$ and $M'$, then $D$ consists of connected components of paths
and even cycles. This is because

\begin{enumerate}
    \item Each vertex in $D$ can be incident on at most two edges : one from $M$
        and one from $M'$, therefore only isolated vertices, cycles and paths
        are possible.
    \item Each path/cycle in $D$ must alternate between $M$ and $M'$ edges
        (since both $M$ and $M'$ themselves are matchings and cannot have two
        edges incident on same vertex)
    \item For a cycle to do this, it must have equal number of edges from $M$
        and $M'$, and therefore be of equal length
\end{enumerate}
Since $M'$ is larger than $M$, $D$ has a component with more edges from $M'$
than $M$. This component is a path that in $G$ that starts and ends with and
edge from $M'$, so it is an augmenting path.

\chapter{Dynamic programming}

\begin{definition}{Strategy for Dynamic Programming}{}
    \begin{enumerate}
        \item Come up with naive/recursive solution
        \item Identify overlapping subproblems
        \item Memoize via table (possibly oversolving, e.g. all Fibonacci less
            than $i$ are computed to compute Fibonacci $i$)
    \end{enumerate}
\end{definition}

\chapter{Journal}

\section{CSES: Two Sets}

\begin{itemize}
    \item \url{https://cses.fi/problemset/task/1092/}
    \item Idea: if the sum of first $n$ numbers is odd, then it is not possible to
        divide them into two subsets of equal sum. The solution when the sum is even is
        to keep picking the largest number from the set of unpicked numbers until the
        sum hits $n(n+1)/4$ and the set of unpicked numbers. The correctness of this
        solution is proved by induction. Complexity $O(nlogn)$.
    \item Faster solution: observe that solution exists only when $n\%4$ is
        either 3 or 0. Figure out exact elements needed to construct in each
        case, complexity $O(n)$.
\end{itemize}

\section{CSES: Nested Ranges Check}
\begin{itemize}
    \item \url{https://cses.fi/problemset/task/2169}
    \item Idea: $R_1$ is contained in $R_2$ iff
        \begin{enumerate}
            \item $R_1$ begins \textit{at least after} $R_2$ begins.
            \item $R_1$ ends \textit{at most before} $R_2$ ends.
        \end{enumerate}
        Sort by increasing beginning of ranges, and break ties by decreasing
        ending of ranges (e.g. $[1, 5]$ comes before $[1, 4]$ and $[2, 6]$ in
        sorted order). Now range at index $k$ begins \textit{at least after} all
        the ranges before it, satisfying the first condition. The second
        condition will be satisfied if $k^{th}$ range ends \textit{at most
        before} any of the preceeding $k-1$ ranges. This can be flipped around
        to equivalently say any of the first $k - 1$ ranges should end
        \textit{at least after} $k^{th}$ range. This can in turn be checked by
        keeping track of the maximum ending and comparing it against $k^{th}$
        range's ending. Observe that if $k^{th}$ range ends strictly after this
        maximum ending, there is no range that containing $k^{th}$ range, due to
        above invariant induced by the sorting and absence of duplicate ranges.
    \item Similarly, $R_1$ contains $R_2$ iff
        \begin{enumerate}
            \item $R_1$ begins \textit{at most before} $R_2$ begins.
            \item $R_1$ ends \textit{at least after} $R_2$ ends.
        \end{enumerate}
        In this case, we iterate backwards after sorting and keep track of the
        minimum instead of maximum.
\end{itemize}

\section{CSES: Factory Machines}
\begin{itemize}
    \item \url{https://cses.fi/problemset/task/1620}
    \item Idea: instead of finding the minimum time, flip the question around by
        asking what are the maximum \# of products that can be produced given
        time $t$? Now the problem reduces to a binary search over $t$. The left
        limit of the search is 0 (when no items are to be produced) and right
        limit the time taken by the fastest machine to produce all the products
        by itself. Calculating \# products that can be produced in a fixed time
        $s$ takes $O(n)$ ($\sum_i floor(s/k_i)$) and the binary search iterates
        for at most $log(min_i(k_i) * t)$ times, making the time complexity
        $O(n * log(min_i(k_i) * t))$.
    \item Interesting to note wholemeal and projective programming lead to the
        solution directly!
\end{itemize}

\section{CSES: Coin Piles}
\begin{itemize}
    \item \url{https://cses.fi/problemset/task/1754}
    \item Idea: WLG, say the two numbers are $x$ and $y$ with $x \leq y$. Then both
        the piles can be made empty iif $y\%x$ is 0, 1 or 2.
\end{itemize}

\end{document}

